{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f155e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n",
      "Pandas version: 2.3.3\n",
      "NumPy version: 2.3.5\n"
     ]
    }
   ],
   "source": [
    "# Libraries & Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69890ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ORIGINAL KAGGLE DATASET\n",
      "============================================================\n",
      "Shape: (284807, 31)\n",
      "Columns (31): ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
      "Memory usage: 67.36 MB\n",
      "Fraud rate: 0.173%\n",
      "Fraud transactions: 492\n",
      "Legitimate transactions: 284,315\n",
      "\n",
      "First 3 rows:\n",
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "\n",
      "         V8        V9       V10       V11       V12       V13       V14  \\\n",
      "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
      "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
      "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
      "\n",
      "        V15       V16       V17       V18       V19       V20       V21  \\\n",
      "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
      "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
      "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
      "\n",
      "        V22       V23       V24       V25       V26       V27       V28  \\\n",
      "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
      "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
      "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
      "\n",
      "   Amount  Class  \n",
      "0  149.62      0  \n",
      "1    2.69      0  \n",
      "2  378.66      0  \n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('../data/raw/creditcard.csv')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ORIGINAL KAGGLE DATASET\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns ({len(df.columns)}): {df.columns.tolist()}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"Fraud rate: {df['Class'].mean()*100:.3f}%\")\n",
    "print(f\"Fraud transactions: {df['Class'].sum():,}\")\n",
    "print(f\"Legitimate transactions: {(df['Class']==0).sum():,}\")\n",
    "print(f\"\\nFirst 3 rows:\\n{df.head(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b73b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction IDs generated\n",
      "Sample IDs: ['txn_66741a9edac3', 'txn_c60411a5aefd', 'txn_6074fbafebe0']\n",
      "Unique IDs: 284,807\n"
     ]
    }
   ],
   "source": [
    "# Transaction IDs\n",
    "df['transaction_id'] = [f'txn_{uuid.uuid4().hex[:12]}' for _ in range(len(df))]\n",
    "\n",
    "print(\"Transaction IDs generated\")\n",
    "print(f\"Sample IDs: {df['transaction_id'].head(3).tolist()}\")\n",
    "print(f\"Unique IDs: {df['transaction_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6262936a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs generated\n",
      "Unique users: 3,958\n",
      "Most active user: 108809 transactions\n",
      "Median user: 2 transactions\n",
      "Top 5 users account for: 67.4% of transactions\n"
     ]
    }
   ],
   "source": [
    "# User IDs with Power-Law Distribution\n",
    "user_indices = np.random.zipf(a=1.5, size=len(df))\n",
    "user_indices = np.clip(user_indices, 1, 10000)\n",
    "df['user_id'] = [f'user_{idx:05d}' for idx in user_indices]\n",
    "\n",
    "user_txn_counts = df['user_id'].value_counts()\n",
    "print(\"User IDs generated\")\n",
    "print(f\"Unique users: {df['user_id'].nunique():,}\")\n",
    "print(f\"Most active user: {user_txn_counts.iloc[0]} transactions\")\n",
    "print(f\"Median user: {user_txn_counts.median():.0f} transactions\")\n",
    "print(f\"Top 5 users account for: {user_txn_counts.head(5).sum()/len(df)*100:.1f}% of transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f0eeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merchant IDs generated\n",
      "Unique merchants: 4,491\n",
      "Highest volume merchant: 72422 transactions\n",
      "Median merchant: 3 transactions\n"
     ]
    }
   ],
   "source": [
    "# Merchant IDs with Power-Law Distribution\n",
    "merchant_indices = np.random.zipf(a=1.3, size=len(df))\n",
    "merchant_indices = np.clip(merchant_indices, 1, 5000)\n",
    "df['merchant_id'] = [f'merchant_{idx:05d}' for idx in merchant_indices]\n",
    "\n",
    "merchant_txn_counts = df['merchant_id'].value_counts()\n",
    "print(\"Merchant IDs generated\")\n",
    "print(f\"Unique merchants: {df['merchant_id'].nunique():,}\")\n",
    "print(f\"Highest volume merchant: {merchant_txn_counts.iloc[0]} transactions\")\n",
    "print(f\"Median merchant: {merchant_txn_counts.median():.0f} transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e366c2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time: 2023-09-02 00:00:00\n",
      "End Time: 2023-09-03 23:59:52\n",
      "\n",
      "Hourly Distribution (First 24h):\n",
      "hour\n",
      "0     3963\n",
      "1     2217\n",
      "2     1576\n",
      "3     1821\n",
      "4     1082\n",
      "5     1681\n",
      "6     1831\n",
      "7     3368\n",
      "8     5179\n",
      "9     7878\n",
      "10    8288\n",
      "11    8517\n",
      "12    7732\n",
      "13    7585\n",
      "14    8029\n",
      "15    7836\n",
      "16    7786\n",
      "17    7882\n",
      "18    8607\n",
      "19    7994\n",
      "20    8980\n",
      "21    9895\n",
      "22    8977\n",
      "23    6082\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Timestamps\n",
    "START_DATE = datetime(2023, 9, 2, 0, 0, 0)\n",
    "df['timestamp'] = df['Time'].apply(lambda x: START_DATE + timedelta(seconds=int(x)))\n",
    "\n",
    "df_temp = df[df['timestamp'] < (START_DATE + timedelta(hours=24))].copy()\n",
    "df_temp['hour'] = df_temp['timestamp'].dt.hour\n",
    "hourly = df_temp.groupby('hour').size()\n",
    "\n",
    "print(f\"Start Time: {df['timestamp'].min()}\")\n",
    "print(f\"End Time: {df['timestamp'].max()}\")\n",
    "print(f\"\\nHourly Distribution (First 24h):\\n{hourly}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d5997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exchange Rate Applied: 88\n",
      "\n",
      "Amount Statistics (INR):\n",
      "count    2.848070e+05\n",
      "mean     7.774766e+03\n",
      "std      2.201057e+04\n",
      "min      0.000000e+00\n",
      "25%      4.928000e+02\n",
      "50%      1.936000e+03\n",
      "75%      6.790520e+03\n",
      "max      2.260822e+06\n",
      "Name: amount_inr, dtype: float64\n",
      "\n",
      "Top 5 Highest Transactions:\n",
      "        amount_inr  Class\n",
      "274771  2260822.08      0\n",
      "58465   1729774.64      0\n",
      "151296  1664080.00      0\n",
      "46841   1136161.84      0\n",
      "54018   1047031.92      0\n"
     ]
    }
   ],
   "source": [
    "# Amount Conversion to INR\n",
    "EXCHANGE_RATE = 88\n",
    "df['amount_inr'] = (df['Amount'] * EXCHANGE_RATE).round(2)\n",
    "\n",
    "print(f\"Exchange Rate Applied: {EXCHANGE_RATE}\")\n",
    "print(f\"\\nAmount Statistics (INR):\\n{df['amount_inr'].describe()}\")\n",
    "print(f\"\\nTop 5 Highest Transactions:\\n{df[['amount_inr', 'Class']].sort_values('amount_inr', ascending=False).head(5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06aa2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Limit: 492.80, High Limit: 17864.00\n",
      "\n",
      "Network Distribution:\n",
      "card_network\n",
      "Visa          0.412816\n",
      "Mastercard    0.411981\n",
      "RuPay         0.167243\n",
      "Amex          0.007960\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Average Amount by Network:\n",
      "card_network\n",
      "RuPay          2481.723191\n",
      "Mastercard     8423.936644\n",
      "Visa           8498.950445\n",
      "Amex          47829.190543\n",
      "Name: amount_inr, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Card Networks\n",
    "low_limit = df['amount_inr'].quantile(0.25)\n",
    "high_limit = df['amount_inr'].quantile(0.90)\n",
    "\n",
    "networks = ['Visa', 'Mastercard', 'RuPay', 'Amex']\n",
    "df['card_network'] = 'Unknown'\n",
    "\n",
    "mask_low = df['amount_inr'] <= low_limit\n",
    "mask_mid = (df['amount_inr'] > low_limit) & (df['amount_inr'] <= high_limit)\n",
    "mask_high = df['amount_inr'] > high_limit\n",
    "\n",
    "df.loc[mask_low, 'card_network'] = np.random.choice(networks, size=mask_low.sum(), p=[0.30, 0.30, 0.40, 0.00])\n",
    "df.loc[mask_mid, 'card_network'] = np.random.choice(networks, size=mask_mid.sum(), p=[0.45, 0.45, 0.10, 0.00])\n",
    "df.loc[mask_high, 'card_network'] = np.random.choice(networks, size=mask_high.sum(), p=[0.45, 0.45, 0.02, 0.08])\n",
    "\n",
    "print(f\"Low Limit: {low_limit:.2f}, High Limit: {high_limit:.2f}\")\n",
    "print(f\"\\nNetwork Distribution:\\n{df['card_network'].value_counts(normalize=True)}\")\n",
    "print(f\"\\nAverage Amount by Network:\\n{df.groupby('card_network')['amount_inr'].mean().sort_values()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1ed0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Card Tier vs Network:\n",
      "card_tier     Classic   Gold  Platinum  Signature\n",
      "card_network                                     \n",
      "Amex                0    657       921        689\n",
      "Mastercard      39212  42227     23309      12587\n",
      "RuPay           22766  16068      6227       2571\n",
      "Visa            39067  42456     23370      12680\n",
      "\n",
      "Average Spending by Tier:\n",
      "card_tier\n",
      "Classic       3778.832181\n",
      "Gold          6081.448667\n",
      "Platinum     13249.125570\n",
      "Signature    17618.662836\n",
      "Name: amount_inr, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Card Tiers\n",
    "tiers = ['Classic', 'Gold', 'Platinum', 'Signature']\n",
    "df['card_tier'] = 'Unknown'\n",
    "\n",
    "mask_amex = df['card_network'] == 'Amex'\n",
    "df.loc[mask_amex, 'card_tier'] = np.random.choice(tiers, size=mask_amex.sum(), p=[0.00, 0.30, 0.40, 0.30])\n",
    "\n",
    "mask_others = df['card_network'] != 'Amex'\n",
    "mask_low_tier = mask_others & (df['amount_inr'] <= low_limit)\n",
    "mask_mid_tier = mask_others & (df['amount_inr'] > low_limit) & (df['amount_inr'] <= high_limit)\n",
    "mask_high_tier = mask_others & (df['amount_inr'] > high_limit)\n",
    "\n",
    "df.loc[mask_low_tier, 'card_tier'] = np.random.choice(tiers, size=mask_low_tier.sum(), p=[0.60, 0.30, 0.08, 0.02])\n",
    "df.loc[mask_mid_tier, 'card_tier'] = np.random.choice(tiers, size=mask_mid_tier.sum(), p=[0.30, 0.40, 0.20, 0.10])\n",
    "df.loc[mask_high_tier, 'card_tier'] = np.random.choice(tiers, size=mask_high_tier.sum(), p=[0.10, 0.20, 0.40, 0.30])\n",
    "\n",
    "print(f\"Card Tier vs Network:\\n{pd.crosstab(df['card_network'], df['card_tier'])}\")\n",
    "print(f\"\\nAverage Spending by Tier:\\n{df.groupby('card_tier')['amount_inr'].mean().sort_values()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa7cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issuer Market Share:\n",
      "card_issuer\n",
      "HDFC Bank             0.268375\n",
      "SBI Card              0.188331\n",
      "ICICI Bank            0.168177\n",
      "Axis Bank             0.139470\n",
      "Kotak Mahindra        0.049465\n",
      "RBL Bank              0.039711\n",
      "IndusInd Bank         0.039595\n",
      "IDFC First            0.039191\n",
      "Yes Bank              0.030062\n",
      "Standard Chartered    0.029662\n",
      "American Express      0.007960\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Amex Issuer Check: ['American Express']\n"
     ]
    }
   ],
   "source": [
    "# Card Issuers\n",
    "banks = ['HDFC Bank', 'SBI Card', 'ICICI Bank', 'Axis Bank', 'Kotak Mahindra', \n",
    "         'IndusInd Bank', 'RBL Bank', 'IDFC First', 'Yes Bank', 'Standard Chartered']\n",
    "probs = [0.27, 0.19, 0.17, 0.14, 0.05, 0.04, 0.04, 0.04, 0.03, 0.03]\n",
    "\n",
    "df['card_issuer'] = np.random.choice(banks, size=len(df), p=probs)\n",
    "df.loc[df['card_network'] == 'Amex', 'card_issuer'] = 'American Express'\n",
    "\n",
    "print(f\"Issuer Market Share:\\n{df['card_issuer'].value_counts(normalize=True)}\")\n",
    "print(f\"\\nAmex Issuer Check: {df[df['card_network'] == 'Amex']['card_issuer'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246c10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merchant Category Distribution:\n",
      "merchant_category\n",
      "Dining         46085\n",
      "Fashion        37114\n",
      "Supermarket    27778\n",
      "Pharmacy       22076\n",
      "Fuel           19920\n",
      "Utility        18453\n",
      "Fast Food      14409\n",
      "Grocery        14227\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Fuel Amount Range:\n",
      "min         0.880000\n",
      "mean     2186.306616\n",
      "max     17864.000000\n",
      "Name: amount_inr, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Merchant Categories\n",
    "df.loc[df['amount_inr'] == 0, 'amount_inr'] = 1.0\n",
    "\n",
    "low_cats = ['Grocery', 'Fast Food', 'Public Transport', 'Fuel', 'Digital Services', 'Pharmacy', 'Entertainment']\n",
    "low_probs = [0.20, 0.20, 0.20, 0.15, 0.15, 0.05, 0.05]\n",
    "\n",
    "mid_cats = ['Dining', 'Fashion', 'Supermarket', 'Pharmacy', 'Utility', 'Fuel', 'Entertainment', 'Auto', 'Personal Care']\n",
    "mid_probs = [0.25, 0.20, 0.15, 0.10, 0.10, 0.05, 0.05, 0.05, 0.05]\n",
    "\n",
    "high_cats = ['Airline', 'Hotel', 'Electronics', 'Jewelry', 'Furniture', 'Hospital']\n",
    "high_probs = [0.30, 0.20, 0.20, 0.10, 0.10, 0.10]\n",
    "\n",
    "df['merchant_category'] = 'Other'\n",
    "df.loc[mask_low, 'merchant_category'] = np.random.choice(low_cats, size=mask_low.sum(), p=low_probs)\n",
    "df.loc[mask_mid, 'merchant_category'] = np.random.choice(mid_cats, size=mask_mid.sum(), p=mid_probs)\n",
    "df.loc[mask_high, 'merchant_category'] = np.random.choice(high_cats, size=mask_high.sum(), p=high_probs)\n",
    "\n",
    "print(f\"Merchant Category Distribution:\\n{df['merchant_category'].value_counts().head(8)}\")\n",
    "print(f\"\\nFuel Amount Range:\\n{df[df['merchant_category'] == 'Fuel']['amount_inr'].describe()[['min', 'mean', 'max']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb921cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Cities:\n",
      "merchant_city\n",
      "Ahmedabad    0.075714\n",
      "Mumbai       0.075672\n",
      "Chennai      0.075174\n",
      "Bengaluru    0.074816\n",
      "Delhi        0.074787\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Top States:\n",
      "merchant_state\n",
      "Maharashtra    54194\n",
      "Gujarat        33024\n",
      "Tamil Nadu     32864\n",
      "Karnataka      21308\n",
      "Delhi          21300\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Geography (City & State)\n",
    "tier1 = ['Mumbai', 'Delhi', 'Bengaluru', 'Chennai', 'Hyderabad', 'Kolkata', 'Pune', 'Ahmedabad']\n",
    "tier2 = ['Jaipur', 'Lucknow', 'Chandigarh', 'Indore', 'Kochi', 'Surat', 'Nagpur', 'Coimbatore', 'Bhopal', 'Patna']\n",
    "tier3 = ['Varanasi', 'Agra', 'Nashik', 'Vadodara', 'Ludhiana', 'Madurai', 'Vizag', 'Guwahati', 'Bhubaneswar', 'Raipur']\n",
    "\n",
    "all_cities = tier1 + tier2 + tier3\n",
    "weights = [0.075]*8 + [0.030]*10 + [0.010]*10\n",
    "\n",
    "df['merchant_city'] = np.random.choice(all_cities, size=len(df), p=weights)\n",
    "\n",
    "city_state_map = {\n",
    "    'Mumbai': 'Maharashtra', 'Pune': 'Maharashtra', 'Nagpur': 'Maharashtra', 'Nashik': 'Maharashtra',\n",
    "    'Delhi': 'Delhi', 'Bengaluru': 'Karnataka',\n",
    "    'Chennai': 'Tamil Nadu', 'Coimbatore': 'Tamil Nadu', 'Madurai': 'Tamil Nadu',\n",
    "    'Hyderabad': 'Telangana', 'Kolkata': 'West Bengal',\n",
    "    'Ahmedabad': 'Gujarat', 'Surat': 'Gujarat', 'Vadodara': 'Gujarat',\n",
    "    'Jaipur': 'Rajasthan',\n",
    "    'Lucknow': 'Uttar Pradesh', 'Agra': 'Uttar Pradesh', 'Varanasi': 'Uttar Pradesh',\n",
    "    'Chandigarh': 'Chandigarh', 'Indore': 'Madhya Pradesh', 'Bhopal': 'Madhya Pradesh',\n",
    "    'Kochi': 'Kerala', 'Patna': 'Bihar', 'Ludhiana': 'Punjab',\n",
    "    'Vizag': 'Andhra Pradesh', 'Guwahati': 'Assam', 'Bhubaneswar': 'Odisha', 'Raipur': 'Chhattisgarh'\n",
    "}\n",
    "\n",
    "df['merchant_state'] = df['merchant_city'].map(city_state_map)\n",
    "\n",
    "print(f\"Top Cities:\\n{df['merchant_city'].value_counts(normalize=True).head(5)}\")\n",
    "print(f\"\\nTop States:\\n{df['merchant_state'].value_counts().head(5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4651dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel Distribution:\n",
      "transaction_channel\n",
      "POS       0.556131\n",
      "Online    0.443869\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Dining Channel Split:\n",
      "transaction_channel\n",
      "POS       0.701183\n",
      "Online    0.298817\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Transaction Channel\n",
    "df['transaction_channel'] = 'POS'\n",
    "\n",
    "online_cats = ['Digital Services', 'Airline', 'Entertainment', 'Public Transport', 'Hotel']\n",
    "pos_cats = ['Fuel', 'Hospital']\n",
    "\n",
    "df.loc[df['merchant_category'].isin(online_cats), 'transaction_channel'] = 'Online'\n",
    "df.loc[df['merchant_category'].isin(pos_cats), 'transaction_channel'] = 'POS'\n",
    "\n",
    "mask_dining = df['merchant_category'] == 'Dining'\n",
    "df.loc[mask_dining, 'transaction_channel'] = np.random.choice(['Online', 'POS'], size=mask_dining.sum(), p=[0.30, 0.70])\n",
    "\n",
    "mask_grocery = df['merchant_category'].isin(['Grocery', 'Supermarket'])\n",
    "df.loc[mask_grocery, 'transaction_channel'] = np.random.choice(['Online', 'POS'], size=mask_grocery.sum(), p=[0.30, 0.70])\n",
    "\n",
    "mask_retail = df['merchant_category'].isin(['Fashion', 'Electronics', 'Furniture', 'Jewelry'])\n",
    "df.loc[mask_retail, 'transaction_channel'] = np.random.choice(['Online', 'POS'], size=mask_retail.sum(), p=[0.50, 0.50])\n",
    "\n",
    "mask_util = df['merchant_category'].isin(['Utility', 'Pharmacy'])\n",
    "df.loc[mask_util, 'transaction_channel'] = np.random.choice(['Online', 'POS'], size=mask_util.sum(), p=[0.60, 0.40])\n",
    "\n",
    "print(f\"Channel Distribution:\\n{df['transaction_channel'].value_counts(normalize=True)}\")\n",
    "print(f\"\\nDining Channel Split:\\n{df[df['merchant_category'] == 'Dining']['transaction_channel'].value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8315ed8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry Mode Statistics:\n",
      "            Total_Txns  Fraud_Count  Fraud_Rate\n",
      "entry_mode                                     \n",
      "CVC             126417          231    0.001827\n",
      "Chip             89513           20    0.000223\n",
      "Swipe             2491          134    0.053794\n",
      "Tap              66386          107    0.001612\n"
     ]
    }
   ],
   "source": [
    "# Entry Mode\n",
    "df['entry_mode'] = 'Unknown'\n",
    "\n",
    "mask_online_ch = df['transaction_channel'] == 'Online'\n",
    "df.loc[mask_online_ch, 'entry_mode'] = 'CVC'\n",
    "\n",
    "mask_gen_pos = (df['Class'] == 0) & (df['transaction_channel'] == 'POS')\n",
    "mask_small = mask_gen_pos & (df['amount_inr'] <= 5000)\n",
    "mask_large = mask_gen_pos & (df['amount_inr'] > 5000)\n",
    "\n",
    "df.loc[mask_small, 'entry_mode'] = np.random.choice(['Tap', 'Chip', 'Swipe'], size=mask_small.sum(), p=[0.585, 0.40, 0.015])\n",
    "df.loc[mask_large, 'entry_mode'] = np.random.choice(['Tap', 'Chip', 'Swipe'], size=mask_large.sum(), p=[0.00, 0.985, 0.015])\n",
    "\n",
    "mask_fraud_pos = (df['Class'] == 1) & (df['transaction_channel'] == 'POS')\n",
    "df.loc[mask_fraud_pos, 'entry_mode'] = np.random.choice(['Swipe', 'Tap', 'Chip'], size=mask_fraud_pos.sum(), p=[0.50, 0.40, 0.10])\n",
    "\n",
    "stats = df.groupby('entry_mode')['Class'].agg(['count', 'sum', 'mean'])\n",
    "stats.columns = ['Total_Txns', 'Fraud_Count', 'Fraud_Rate']\n",
    "print(f\"Entry Mode Statistics:\\n{stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8c8e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recurring Distribution:\n",
      "is_recurring\n",
      "0    257814\n",
      "1     26993\n",
      "Name: count, dtype: int64\n",
      "\n",
      "International by Class:\n",
      "Class\n",
      "0    0.016717\n",
      "1    0.213415\n",
      "Name: is_international, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Boolean Flags\n",
    "df['is_recurring'] = 0\n",
    "mask_util_rec = df['merchant_category'] == 'Utility'\n",
    "df.loc[mask_util_rec, 'is_recurring'] = 1\n",
    "\n",
    "mask_digital = df['merchant_category'] == 'Digital Services'\n",
    "df.loc[mask_digital, 'is_recurring'] = np.random.choice([1, 0], size=mask_digital.sum(), p=[0.8, 0.2])\n",
    "\n",
    "df['is_international'] = 0\n",
    "mask_gen = df['Class'] == 0\n",
    "mask_fraud = df['Class'] == 1\n",
    "\n",
    "df.loc[mask_gen, 'is_international'] = np.random.choice([0, 1], size=mask_gen.sum(), p=[0.98, 0.02])\n",
    "df.loc[mask_fraud, 'is_international'] = np.random.choice([0, 1], size=mask_fraud.sum(), p=[0.75, 0.25])\n",
    "\n",
    "mask_rupay = df['card_network'] == 'RuPay'\n",
    "df.loc[mask_rupay, 'is_international'] = 0\n",
    "\n",
    "print(f\"Recurring Distribution:\\n{df['is_recurring'].value_counts()}\")\n",
    "print(f\"\\nInternational by Class:\\n{df.groupby('Class')['is_international'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0561844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Credit Limit by Tier:\n",
      "card_tier\n",
      "Classic      6.244113e+04\n",
      "Gold         1.996596e+05\n",
      "Platinum     5.250720e+05\n",
      "Signature    1.123149e+06\n",
      "Name: credit_limit, dtype: float64\n",
      "\n",
      "Card Age Distribution (Sample):\n",
      "card_age\n",
      "1    4695\n",
      "2    4774\n",
      "3    4801\n",
      "4    4696\n",
      "5    4797\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Card Profile Details\n",
    "df['card_age'] = np.random.randint(1, 61, size=len(df))\n",
    "\n",
    "limits = {\n",
    "    'Classic': (25000, 100000),\n",
    "    'Gold': (100000, 300000),\n",
    "    'Platinum': (300000, 750000),\n",
    "    'Signature': (750000, 1500000)\n",
    "}\n",
    "\n",
    "df['credit_limit'] = 0\n",
    "for tier, (low, high) in limits.items():\n",
    "    mask_tier = df['card_tier'] == tier\n",
    "    df.loc[mask_tier, 'credit_limit'] = (np.random.randint(low, high, size=mask_tier.sum()) // 1000) * 1000\n",
    "\n",
    "mask_over_limit = df['amount_inr'] > df['credit_limit']\n",
    "df.loc[mask_over_limit, 'credit_limit'] = (df.loc[mask_over_limit, 'amount_inr'] * 1.2).astype(int)\n",
    "\n",
    "print(f\"Average Credit Limit by Tier:\\n{df.groupby('card_tier')['credit_limit'].mean().sort_values()}\")\n",
    "print(f\"\\nCard Age Distribution (Sample):\\n{df['card_age'].value_counts().sort_index().head(5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b4e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Shape: (284807, 46)\n",
      "Columns: 46\n",
      "Column List: ['transaction_id', 'user_id', 'merchant_id', 'timestamp', 'card_network', 'card_issuer', 'card_tier', 'credit_limit', 'card_age', 'amount_inr', 'merchant_category', 'merchant_city', 'merchant_state', 'transaction_channel', 'entry_mode', 'is_international', 'is_recurring', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'is_fraud']\n",
      "\n",
      "Fraud Distribution:\n",
      "is_fraud\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Final Cleanup & Reordering\n",
    "df = df.rename(columns={'Class': 'is_fraud'})\n",
    "df = df.drop(columns=['Time', 'Amount'], errors='ignore')\n",
    "\n",
    "cols_id = ['transaction_id', 'user_id', 'merchant_id', 'timestamp']\n",
    "cols_card = ['card_network', 'card_issuer', 'card_tier', 'credit_limit', 'card_age']\n",
    "cols_txn = ['amount_inr', 'merchant_category', 'merchant_city', 'merchant_state', \n",
    "            'transaction_channel', 'entry_mode', 'is_international', 'is_recurring']\n",
    "cols_pca = [f'V{i}' for i in range(1, 29)]\n",
    "cols_target = ['is_fraud']\n",
    "\n",
    "final_order = cols_id + cols_card + cols_txn + cols_pca + cols_target\n",
    "final_order = [c for c in final_order if c in df.columns]\n",
    "df = df[final_order]\n",
    "\n",
    "print(f\"Final Shape: {df.shape}\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "print(f\"Column List: {df.columns.tolist()}\")\n",
    "print(f\"\\nFraud Distribution:\\n{df['is_fraud'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7781e2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to: ../data/processed/transactions_enriched.parquet\n",
      "File Size: 76.14 MB\n"
     ]
    }
   ],
   "source": [
    "# Save Data\n",
    "import os\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "save_path = '../data/processed/transactions_enriched.parquet'\n",
    "df.to_parquet(save_path, index=False)\n",
    "\n",
    "print(f\"Dataset saved to: {save_path}\")\n",
    "print(f\"File Size: {os.path.getsize(save_path) / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30e1922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "realtime-fraud-detection-mlops (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
